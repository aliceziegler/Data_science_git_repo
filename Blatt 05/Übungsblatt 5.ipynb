{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Übungsblatt 5 #\n",
    "\n",
    "### Alice Ziegler, Daniel Schneider ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 5.1: Regression ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laden und Vorbereiten des `Wilt`-Datensatzes ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"wilt/training.csv\")\n",
    "testing = pd.read_csv(\"wilt/testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training['class'] = training['class'].astype(dtype=\"category\")\n",
    "testing['class'] = testing['class'].astype(dtype=\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4339 entries, 0 to 4338\n",
      "Data columns (total 6 columns):\n",
      "class         4339 non-null category\n",
      "GLCM_pan      4339 non-null float64\n",
      "Mean_Green    4339 non-null float64\n",
      "Mean_Red      4339 non-null float64\n",
      "Mean_NIR      4339 non-null float64\n",
      "SD_pan        4339 non-null float64\n",
      "dtypes: category(1), float64(5)\n",
      "memory usage: 173.8 KB\n"
     ]
    }
   ],
   "source": [
    "training.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 6 columns):\n",
      "class         500 non-null category\n",
      "GLCM_pan      500 non-null float64\n",
      "Mean_Green    500 non-null float64\n",
      "Mean_Red      500 non-null float64\n",
      "Mean_NIR      500 non-null float64\n",
      "SD_pan        500 non-null float64\n",
      "dtypes: category(1), float64(5)\n",
      "memory usage: 20.1 KB\n"
     ]
    }
   ],
   "source": [
    "testing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Lernen einer Regressionsfunktion ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def regression(data,targetAttribute):\n",
    "            \n",
    "    t = data[[targetAttribute]].as_matrix()\n",
    "    #print(t)\n",
    "    \n",
    "    D = data.drop([targetAttribute],axis=1).as_matrix()\n",
    "    ones = np.ones((D.shape[0]))\n",
    "    #print(ones)\n",
    "    \n",
    "    D = np.c_[ones,D]\n",
    "    #print(D)\n",
    "    \n",
    "    DT = np.transpose(D)\n",
    "    \n",
    "    w = np.dot(np.dot(np.linalg.inv(np.dot(DT, D)), DT), t)\n",
    "    #print(w)\n",
    "    return (w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateValues(data, ws):\n",
    "    Xs = data.as_matrix()\n",
    "    ones = np.ones((Xs.shape[0]))\n",
    "    \n",
    "    Xs = np.c_[ones,Xs]\n",
    "        \n",
    "    t = np.dot(Xs, ws)\n",
    "    #print(t)\n",
    "    return(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w1 = regression(training.iloc[:,1:6],'SD_pan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts = testing[['SD_pan']].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsCalc = calculateValues(testing.iloc[:,1:5],w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) MDS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def regressionWithClasses(data,targetAttribute,classAttribute):\n",
    "    \n",
    "    datas = groupByClasses(data,classAttribute)\n",
    "    w = [None]*len(datas)\n",
    "    \n",
    "    for i in range(0,len(datas)):        \n",
    "        w[i] = regression(datas[i].drop([classAttribute],axis=1),targetAttribute)\n",
    "    \n",
    "    return (w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2 = regressionWithClasses(training.iloc[:,0:6],'SD_pan','class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def groupByClasses(data,classAttribute):\n",
    "    cats = data[classAttribute].cat.categories\n",
    "\n",
    "    dataClass = [None]*len(cats)\n",
    "    \n",
    "    for i in range(0,len(cats)):\n",
    "        dataClass[i] = data.loc[testing[classAttribute] == cats[i]]\n",
    "    \n",
    "    return(dataClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testingClasses = groupByClasses(testing,'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsClasses = [None]*len(testingClasses)\n",
    "tsCalcClasses = [None]*len(testingClasses)\n",
    "\n",
    "for i in range(0,len(testingClasses)):\n",
    "    tsClasses[i] = testingClasses[i][['SD_pan']].as_matrix()\n",
    "    tsCalcClasses[i] = calculateValues(testingClasses[i].iloc[:,1:5],w2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Stress ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squareError(tLearned,tOrig):\n",
    "    err = 0.5*np.sum(np.square(tLearned-tOrig))\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16676.6852235\n"
     ]
    }
   ],
   "source": [
    "squareError(tsCalc,ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12323.7864823\n",
      "2396.73156755\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(testingClasses)):\n",
    "    squareError(tsCalcClasses[i],tsClasses[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 4.2: Distanzmaße ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Beweis: Gemischte Distanzfunktion ist eine Metrik ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sei $p$ die Anzahl der Attribute unterschiedlichen Typs.\n",
    " \n",
    "Zu zeigen: Die Funktion $ d: X \\times X \\to \\mathbb {R} $ mit\n",
    "\n",
    "$$\n",
    "d(x_i,x_j) = \\frac{\\sum_{f=1}^p \\delta_{ij}^{(f)} d_{ij}^{(f)}} {\\sum_{f=1}^p \\delta_{ij}^{(f)}}\n",
    "$$\n",
    "\n",
    "ist eine Metrik, wenn $d_{ij}^{(f)}$ metrisch ist.\n",
    "\n",
    "\n",
    "\n",
    "Es müssen dafür die folgenden 3 Axiome gelten:\n",
    "\n",
    "1. Positive Definitheit: \n",
    "$d (x_i, x_j) \\geq 0$ und $d (x_i, x_j) = 0 \\Leftrightarrow x_i = x_j$\n",
    "\n",
    "2. Symmetrie: \n",
    "$d (x_i, x_j) = d (x_j, x_i)$\n",
    "\n",
    "3. Dreiecksungleichung: \n",
    "$d (x_i, x_j) \\leq d (x_i, x_k) + d (x_k, x_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es sei $d_{ij}^{(f)}$ eine Metrik. Dann dürfen keine $x_{if}$ undefiniert sein, da alle Distanzen bestimmbar sein müssen.\n",
    "\n",
    "**Zu 1. **\n",
    "\n",
    "Zu zeigen: $d (x_i, x_j) \\geq 0$\n",
    "\n",
    "* Nach Voraussetzung gilt: $d_{ij}^{(f)} \\geq 0$ für alle $f \\in \\{1,...,p\\}$.\n",
    "\n",
    "  Für den binären Indikator $\\delta_{ij}^{(f)}$ gilt nach Definition: \n",
    "\n",
    "     $\\delta_{ij}^{(f)} \\in {0,1}$ für alle $i,j \\in \\{1,...,n\\}$ und $f \\in \\{1,...,p\\}$, also $\\delta_{ij}^{(f)} \\geq 0$\n",
    "\n",
    "   Daraus folgt: \n",
    "   $$\n",
    "   \\frac{\\sum_{f=1}^p \\delta_{ij}^{(f)} d_{ij}^{(f)}} {\\sum_{f=1}^p \\delta_{ij}^{(f)}} \\geq 0 \\Leftrightarrow d (x_i, x_j) \\geq 0\n",
    "   $$ \n",
    "\n",
    "\n",
    "Noch zu zeigen: $d (x_i, x_j) = 0 \\Leftrightarrow x_i = x_j$. Zeige dazu beide Richtungen:\n",
    "\n",
    "* $\\Leftarrow$\n",
    "\n",
    "  Wenn $x_i = x_j$, dann folgt, weil $d_{ij}^{(f)}$ metrisch ist, dass $d_{ij}^{(f)} = 0$ für alle $f \\in \\{1,...,p\\}$ und daraus folgt: $\\frac{\\sum_{f=1}^p \\delta_{ij}^{(f)} d_{ij}^{(f)}} {\\sum_{f=1}^p \\delta_{ij}^{(f)}} = 0 \\Leftrightarrow d (x_i, x_j) = 0$ \n",
    "\n",
    "\n",
    "* $\\Rightarrow$\n",
    "\n",
    "  Sei nun $d (x_i, x_j) = 0$, dann muss $\\sum_{f=1}^p \\delta_{ij}^{(f)} d_{ij}^{(f)} = 0$ sein. Betrachte zwei Fälle:\n",
    "\n",
    "  1. Falls $d_{ij}^{(f)} = 0$ für alle $f \\in \\{1,...,p\\}$ gilt nach Voraussetzung $x_i = x_j$.\n",
    "\n",
    "  2. Angenommen es gäbe ein $f_x \\in \\{1,...,p\\}$ sodass $d_{ij}^{(f_x)} \\neq 0$. Dann folgt daraus, dass $\\delta_{ij}^{(f_x)} = 0$ sein muss. Dies ist allerdings nur der Fall, wenn $x_{if_x} = x_{jf_x}$ (für ein binäres asymetrisches Attribut $f_x$). Und dann gilt weiterhin $x_i = x_j$.\n",
    "\n",
    "\n",
    "* Zusammen gilt also: \n",
    "$$\n",
    "d (x_i, x_j) = 0 \\Leftrightarrow x_i = x_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zu 2.**\n",
    "\n",
    "Zu zeigen: $d (x_i, x_j) = d (x_j, x_i)$\n",
    "\n",
    "* Nach Voraussetzung gilt: $d_{ij}^f = d_{ji}^f$ für alle $f \\in \\{1,...,p\\}$\n",
    "\n",
    "  Und auch für $\\delta_{ij}^{(f)}$ gilt nach Definition, dass $\\delta_{ij}^{(f)} = \\delta_{ji}^{(f)}$ für alle $i,j \\in \\{1,...,n\\}$ und $f \\in \\{1,...,p\\}$\n",
    "\n",
    "  Also gilt auch: $\\sum_{f=1}^p \\delta_{ij}^{(f)} d_{ij}^{(f)} = \\sum_{f=1}^p \\delta_{ij}^{(f)} d_{ji}^{(f)}$\n",
    "  \n",
    "  Und daraus folgt: \n",
    "  $$\n",
    "  \\frac{\\sum_{f=1}^p \\delta_{ij}^{(f)} d_{ij}^{(f)}} {\\sum_{f=1}^p \\delta_{ij}^{(f)}} = \\frac{\\sum_{f=1}^p \\delta_{ji}^{(f)} d_{ji}^{(f)}} {\\sum_{f=1}^p \\delta_{ji}^{(f)}} \\Leftrightarrow d (x_i, x_j) = d (x_j, x_i)\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zu 3.**\n",
    "\n",
    "Zu zeigen: $d (x_i, x_j) \\leq d (x_i, x_k) + d (x_k, x_j)$\n",
    "\n",
    "* Nach Voraussetzung gilt: $d_{ij}^f \\leq d_{ik}^f + d_{kj}^f$ für alle $f \\in \\{1,...,p\\}$\n",
    "  \n",
    "  Für $\\delta_{ij}^{(f)}$ wiederum gilt:\n",
    "  \n",
    "  Falls $\\delta_{ik}^{(f)} = 0$ oder $\\delta_{kj}^{(f)} = 0$ folgt daraus, dass auch $\\delta_{ij}^{(f)} = 0$ sein muss, da die Null nur angenommen wird, wenn zwei Attribute übereinstimmen. Es gilt also (da $\\delta_{ik}^{(f)} \\in \\{0,1\\}$) : $\\delta_{ij}^{(f)} \\leq \\delta_{ik}^{(f)} + \\delta_{kj}^{(f)}$.\n",
    "  \n",
    "  Und daraus folgt:\n",
    "  $$\n",
    "  \\frac{\\sum_{f=1}^p \\delta_{ij}^{(f)} d_{ij}^{(f)}} {\\sum_{f=1}^p \\delta_{ij}^{(f)}} \\leq \n",
    "  \\frac{\\sum_{f=1}^p \\delta_{ik}^{(f)} d_{ik}^{(f)}} {\\sum_{f=1}^p \\delta_{ik}^{(f)}} + \\frac{\\sum_{f=1}^p \\delta_{kj}^{(f)} d_{kj}^{(f)}} {\\sum_{f=1}^p \\delta_{kj}^{(f)}}\n",
    "  \\Leftrightarrow\n",
    "  d (x_i, x_j) \\leq d (x_i, x_k) + d (x_k, x_j)\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Speicherkomplexität von Distanzmatrizen ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Speicherkomplexität der Distanzmatrix für $n$ Werte beträgt $O(n^2)$\n",
    "\n",
    "Durch die symmetrie der Distanzen entspricht die Distanz von $x_i$ nach $x_j$ genau der von $x_j$ nach $x_i$ ($d_{ij}=d_{ji}$). \n",
    "\n",
    "Daher steht jeder Distanzwert zwei Mal in der Matrix, einmal an Position $i,j$ und noch einmal an Position $j,i$. Man könnte zwar jeden Wert auch nur einmal speichern, also nur die Position $i,j$ belegen und die Position $j,i$ leer lassen, dadurch wird allerdings die Matrix nicht kleiner, sie enthält nur weniger Werte (mehr NULL-Werte). Den Speicherverbrauch reduziert diese Lösung also nicht wirklich.\n",
    "\n",
    "Um wirklich Speicherplatz einzusparen müsste man also eine andere Datenstruktur als eine Matrix wählen, sodass die doppelten Werte nur einmal gespeichert werden müssen, aber auch keine leeren Felder entstehen.\n",
    "\n",
    "Beispielsweise könnte man eine Liste mit Dreiertupeln verwenden, sodass jedes Tupel eine Distanz enthält und zu jedem Distanzeintrag die beiden betreffenden Punkte (Start und Ende). Eine solche Lösung kann allerdings zu anderen Problemen führen: Wenn beispielsweise ein durchgängier Pfad verfolgt werden soll, zm dessen Distanz aufzuaddieren, ist es sehr viel aufwändiger, zu einem Endpunkt wieder den nächsten Startpunkt zu ermitteln, da jetzt jedes Mal zwei Spalten mit möglichen Punkten durchsucht werden müssen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Aufgabe 4.3: Verzerrte Werte ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Nicht-Erwartungstreue des Schätzers der Varianz ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "Wiederlegung\\ Erwartungstreue\\ Varianz: \\\\\n",
    "s^2 = Var(x_i) &= {\\frac{{\\sum_{i=1}^N{(x_i-µ)^2}}}{N}} \\\\\n",
    "E(Var(x_i)) &= E({\\frac{{\\sum_{i=1}^N{(x_i-µ)^2}}}{N}}) \\\\\n",
    "&= {\\frac{1}{N}}E({\\sum_{i=1}^N{(x_i-µ)^2}})\\\\\n",
    "&= {\\frac{1}{N}} {\\sum_{i=1}^N{(E(x_i^2)-2E(x_iµ)+E(µ^2))}} \\\\\n",
    "&= {\\frac{1}{N}}{\\sum_{i=1}^N{((Var(x_i)+µ^2)\\ (siehe\\ I)\\\\ \n",
    "- 2({\\frac{Var(x_i)}{N}}+µ^2)\\  (siehe\\ II)\\\\\n",
    "+ {\\frac{Var(x_i)}{N}} + µ^2)}}\\ (siehe\\ III)\\\\\n",
    "&= {\\frac{1}{N}}{\\sum_{i=1}^N{((Var(x_i)+µ^2) - 2({\\frac{Var(x_i)}{N}}+µ^2)+{\\frac{Var(x_i}{N}}+µ^2)}} \\\\\n",
    "&= {\\frac{1}{N}}{\\sum_{i=1}^N{(Var(x_i)+µ^2-{\\frac{2Var(x_i)}{N}}-2µ^2 + {\\frac{Var(x_i)}{N}} + µ^2)}} \\\\\n",
    "&= {\\frac{1}{N}}{\\sum_{i=1}^N{(Var(x_i)-{\\frac{2Var(x_i)}{N}}+ {\\frac{Var(x_i)}{N}})}} \\\\\n",
    "&= {\\frac{1}{N}}{\\sum_{i=1}^N({Var(x_i)-{\\frac{Var(x_i)}{N}})}} \\\\\n",
    "&= {\\frac{1}{N}}(N Var(x_i) - {\\frac{N Var(x_i}{N}} \\\\\n",
    "&= Var(x_i) - {\\frac{Var(x_i)}{N}} \\\\\n",
    "&= Var(x_i) (1-{\\frac{1}{N}}) \\\\\n",
    "&= Var(x_i) ({\\frac{N-1}{N}}) \\\\\n",
    "\\\\\n",
    "bias &= Var(x_i) (1-{\\frac{1}{N}} - Var(x_i) \\\\\n",
    "bias &= Var(x_i) - {\\frac{Var(x_i)}{N}}- Var(x_i) \\\\\n",
    "bias &= - {\\frac{Var(x_i)}{N}} \\\\\n",
    "bias &\\neq 0 ==> nicht\\ Erwartungstreu\n",
    "\\\\\n",
    "\\\\\n",
    "Grundlage\\ I: \\\\\n",
    "(Verschiebungssatz) \\\\\n",
    "Var(X_i) &= E(X_i^2) - E(X_i)^2 \\\\\n",
    "E(X_i^2) &= Var(X_i) + E(X_i)^2 \\\\\n",
    "wobei: \\\\ \n",
    "E(X_i)^2 &= µ^2 \\\\\n",
    "\\\\\n",
    "Grundlage\\ II: \\\\\n",
    "E(x_iµ) &= \\frac{1}{N}{\\sum_{j=1}^N{E(x_ix_j)}} \\\\\n",
    "&= \\frac{1}{N}E(x_i^2)+{\\frac{1}{N}}{\\sum_{j=1...N;\\ (j\\neq i)}E(x_i)E(x_j)} \\\\\n",
    "&= \\frac{1}{N}(Var(x_i) + E(x_i)^2) + \\frac{1}{N}µ(N-1)µ \\\\\n",
    "&= \\frac{1}{N}(Var(x_i) + µ^2) + \\frac{1}{N}(N-1)µ^2 \\\\\n",
    "&= {\\frac{Var(x_i)+µ^2+Nµ^2-µ^2}{N}} \\\\\n",
    "&= {\\frac{Var(x_i)}{N}}+µ^2 \\\\\n",
    "\\\\\n",
    "Grundlage\\ III: \\\\\n",
    "E(µ^2) &= {\\frac{1}{N^2}}{\\sum_{i,j = 1}^N{E(x_ix_j)}} \\\\\n",
    "&= {\\frac{1}{N^2}}({\\sum_{i=1}^N{E(x_i^2)}} + {\\sum_{j=1...N;\\ (j\\neq i)}{E(x_i)E(x_j)}}) \\\\\n",
    "&= {\\frac{1}{N^2}}({\\sum_{i=1}^N{(Var(x_i)+E(x_i)^2)}}+ µ(N-1)µ)\\\\\n",
    "&= {\\frac{1}{N^2}}(N(Var(x_i)+E(x_i)^2)+N(N-1)µ^2) \\\\\n",
    "&= {\\frac{N Var(x_i)+N µ^2 + N^2µ^2-µ^2N}{N^2}} \\\\\n",
    "&= {\\frac{1}{N}}(Var(x_i)+µ^2+Nµ^2-µ^2) \\\\\n",
    "&= {\\frac{Var(x_i)}{N}}+µ^2\n",
    "\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Korrektur des Schätzers ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Schätzer der Varianz ist \n",
    "$$\n",
    "\\begin{align}\n",
    "s^2 = Var(x_i) &= {\\frac{{\\sum_{i=1}^N{(x_i-µ)^2}}}{N}} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "Aus Aufgabe a) geht hervor: \n",
    "$$\n",
    "\\begin{align}\n",
    "E(Var(x_i)) &= Var(x_i) ({\\frac{N-1}{N}}) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "Damit die Verzerrung des Schätzers eliminiert würde müsste \n",
    "$$\n",
    "\\begin{align}\n",
    "E(Var(x_i)) &= Var(x_i) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "sein. \n",
    "\n",
    "#### Korrektur des Schätzers: \n",
    "$$\n",
    "\\begin{align}\n",
    "Var(x_i) &= {\\frac{{\\sum_{i=1}^N{(x_i-µ)^2}}}{N}} ({\\frac{N}{N-1}})\\\\\n",
    "Var(x_i) &= {\\frac{\\sum_{i = 1}^N{(x_i - µ)^2}}{N-1}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
